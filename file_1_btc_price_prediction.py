# -*- coding: utf-8 -*-
"""File_1_BTC_Price_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NGjA41_DZBvOUH_q_o8SrEfCKc_Jha6J
"""

# The file utilizes Bitcoin price daily data, return predictions and save them along with actual data to csv file

# The model to predict daily (24h) Bitcoin close price.
# The final prediction model consits of 2 models:
# 1. Regression LSTM model which uses only Bitcoin close price data (window size = 10).
# 2. Regression LSTM model which uses multivariate data (Bitcoin close price and Fear and Greed Index).
# The models are combined using multiple linear regression.

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
pip install scikit-learn==0.22.2.post1
# Commented out IPython magic to ensure Python compatibility.
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM
from keras.models import load_model
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests
from joblib import dump, load
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
# %matplotlib inline

# Specify the datafile which is used as input, for further return of predictions
file = r'C:\Users\ketap\Downloads\drive-download-20200322T222027Z-001\BTCUSD_1d_2011-09-13_to_2019-10-23_bitstamp.csv'

# # Commented out IPython magic to ensure Python compatibility.
# # Connect to Google drive, to upload the data
# from google.colab import drive
# drive.mount('/content/gdrive')
# # %cd /content/gdrive/My\ Drive/Colab\ Notebooks/data

# Function for data preprocessing. Returns 4 variables: X1 (for model 1), X2 (dataframe for model 2), y (actual y) and scaler for further use inside the model
def preprocess(file_path_name):
  
  filename = str(file_path_name)
  data = pd.read_csv(filename)
  data['date'] = pd.to_datetime(data['date'])
  df = data.filter(items=['date', 'close'])
  df = df.dropna(axis = 0, how ='any') 
  df.index = df.date
  df.drop('date', axis=1, inplace=True)
  x = df.values

  # Normalize the data
  scaler = MinMaxScaler(feature_range=(0, 1))
  scaled = scaler.fit_transform(x)

  # Data preparation for further use in the LSTM model
  # X1 is vector of inputs, y is labels (values needed to be predicted)
  X1 = []
  y = []
  # History_size if a number of previous time steps to use as input variables
  history_size = 10
  for i in range(history_size, len(scaled)):
    X1.append(scaled[i - history_size:i, 0])
    y.append(scaled[i])
  X1, y = np.array(X1), np.array(y)
  X1 = np.reshape(X1, (X1.shape[0], X1.shape[1], 1))

  # Load Fear and Greed Index historical data using API
  url = 'https://api.alternative.me/fng/'
  resp = requests.get(url,params={'limit': '2000', 'format': 'csv', 'date_format': 'cn'})

  resp_list = []
  for line in resp.text.splitlines():
    resp_list.append(line)
  resp_list = resp_list[4:-5]
  fg_df = pd.DataFrame([sub.split(",") for sub in resp_list])
  fg_df.columns = ['Date', 'F&G Index', 'Outcome']
  fg_df['Date'] = pd.to_datetime(fg_df['Date'])
  fg_df = fg_df.set_index('Date')
  fg_df = fg_df.drop(['Outcome'], axis = 1)
  fg_df["F&G Index"] = fg_df["F&G Index"].astype(float)
  fg_df = fg_df.sort_index(ascending=True)
  # Temporal alignment of F&G Index with Bitcoin price data and combining then into one data frame
  fg_df_new = fg_df.loc[:df.index.max()]
  fg_df_new = fg_df_new.join(df, lsuffix='_date1', rsuffix='_date2')
  fg_df_new = fg_df_new[['close', 'F&G Index']]
  fg_df_new = fg_df_new.dropna()
  X2 = fg_df_new

  return X1, X2, y, scaler

# Preprocess the given data
X1, X2, y, scaler = preprocess(file)
y = scaler.inverse_transform(y)

# Function which loads the model and the data, and returns the array of predictions (Model 1)
def model(file_path_name, input):
  lstm_model = load_model(str(file_path_name))
  y1_hat = lstm_model.predict(input)
  y1_hat = scaler.inverse_transform(y1_hat)
  return y1_hat

# Load the Model 1 file and make predictions for X1
y1_hat = model(r'C:\Users\ketap\Downloads\drive-download-20200322T222027Z-001\Bitcoin_LSTM_w10d_final.h5', X1)

# Function which loads the model and the data, and returns the array of predictions (Model 2: uses Bitcoin price and Fear&Greed Index)
# Lookback period = 1
def additional_model(file_path_name, input):
  scaled= scaler.fit_transform(input)
  scaled = pd.DataFrame(scaled)

  lookback = 1
  pred_col = 0
  t = scaled.copy()
  t['id'] = range(1, len(scaled) + 1)
  t = t.iloc[:-lookback,:]
  t.set_index('id', inplace=True)
  pred_value = scaled.copy()
  pred_value = pred_value.iloc[lookback:, pred_col]
  pred_value.columns = ["Pred"]
  pred_value = pd.DataFrame(pred_value)
  pred_value["id"] = range(1, len(pred_value) + 1)
  pred_value.set_index('id', inplace=True)
  final_df = pd.concat([t, pred_value], axis=1)
  values = final_df.values
  x = values[:,:-1]
  x = np.reshape(x, (x.shape[0], x.shape[1], 1))

  add_model = load_model(str(file_path_name))

  y2_hat = add_model.predict(x)
  x = x.reshape((x.shape[0], x.shape[1]))
  y2_hat = np.concatenate((y2_hat, x[:,1:]), axis=1)
  y2_hat = scaler.inverse_transform(y2_hat)
  y2_hat = y2_hat[:,0]
  y2_hat = y2_hat.reshape(-1,1)
  return y2_hat

# Load the Model 2 file and make predictions for X2
y2_hat = additional_model(r'C:\Users\ketap\Downloads\drive-download-20200322T222027Z-001\Bitcoin_and_FG_Index_2.h5', X2)

# Function loads Model 3 (simple linear model) weights and makes prediction based on y1_hat (obtained from Model 1) and y2_hat (obtained from Model 2)4
# Returns y3_hat - the improved predictions
def combiner(file_path_name, y1_hat, y2_hat):
  if y1_hat.shape[0] > y2_hat.shape[0]:
    y1_hat_aligned = y1_hat[-y2_hat.shape[0]:]
    y2_hat_aligned = y2_hat
  elif y1_hat.shape[0] < y2_hat.shape[0]:
    y2_hat_aligned = y2_hat[-y1_hat.shape[0]:]
    y1_hat_aligned = y1_hat
  else:
    y2_hat_aligned = y2_hat
    y1_hat_aligned = y1_hat
    
  model_final = load(str(file_path_name))
  y3_hat = model_final.predict(np.concatenate((y1_hat_aligned, y2_hat_aligned), axis=1))
  return y3_hat

y3_hat = combiner(r'C:\Users\ketap\Downloads\drive-download-20200322T222027Z-001\LinearCombiner3.joblib', y1_hat, y2_hat)

y_aligned = y[-y3_hat.shape[0]:]
# Plot the graph of actual vs predicted values
fig = plt.figure(figsize=[20,12])
ax = fig.add_subplot(111)
time_steps = np.arange(1, len(y3_hat) + 1)
plt.plot(time_steps, y_aligned, label = 'Actual price')
plt.plot(time_steps, y3_hat, label = 'Predicted price')
ax.legend()
plt.show()

# MSE obtained by the LSTM model
mse = mean_squared_error(y_aligned, y3_hat)
mse

# Naive forecast function
def persistence_model(x):
    return x[:-1]

y_aligned[1:]
# MSE obtained by naive forecast model
mse_1 = mean_squared_error(y_aligned[1:], persistence_model(y_aligned))
mse_1

# Create a dataframe containing date, actual close price, F&G index and predicted close price
df = X2[-y3_hat.shape[0]:]
df.loc[:,'close forecast'] = y3_hat
df.reset_index(level=0, inplace=True)
df = df.rename(columns={"index": "date"})

# Join the predictions and the original data file, delete missing values and save the result into csv file
data = pd.read_csv(file)
data['date'] = pd.to_datetime(data['date'])
data = data.join(df.drop(columns=['close', 'F&G Index']).set_index('date'), on='date').dropna().reset_index(drop=True)
data.to_csv(r'C:\Users\ketap\Downloads\drive-download-20200322T222027Z-001\BTC_data_and_forecast.csv', index=False)
